I1229 16:59:22.097897  7974 caffe.cpp:297] Use GPU with device ID 0
==7974== NVPROF is profiling process 7974, command: ./caffe/build/tools/caffe time --model=proto_forceGradInput/conv4.prototxt --iterations=1 --gpu 0 --logtostderr=1
I1229 16:59:22.850082  7974 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: proto_forceGradInput/conv4.prototxt
I1229 16:59:22.850200  7974 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
I1229 16:59:22.850332  7974 net.cpp:50] Initializing net from parameters: 
name: "ConvLayer_128x128x7x7"
input: "data"
input_dim: 128
input_dim: 128
input_dim: 16
input_dim: 16
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "data"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
I1229 16:59:22.850395  7974 net.cpp:435] Input 0 -> data
I1229 16:59:22.862444  7974 layer_factory.hpp:76] Creating layer conv4
I1229 16:59:22.862495  7974 net.cpp:110] Creating Layer conv4
I1229 16:59:22.862510  7974 net.cpp:477] conv4 <- data
I1229 16:59:22.862531  7974 net.cpp:433] conv4 -> conv4
I1229 16:59:22.873469  7974 net.cpp:155] Setting up conv4
I1229 16:59:22.873512  7974 net.cpp:163] Top shape: 128 128 10 10 (1638400)
I1229 16:59:22.873545  7974 net.cpp:240] conv4 does not need backward computation.
I1229 16:59:22.873558  7974 net.cpp:283] This network produces output conv4
I1229 16:59:22.873572  7974 net.cpp:297] Network initialization done.
I1229 16:59:22.873581  7974 net.cpp:298] Memory required for data: 6553600
I1229 16:59:22.873610  7974 caffe.cpp:309] Performing Forward
==7974== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
I1229 17:00:35.950990  7974 caffe.cpp:314] Initial loss: 0
I1229 17:00:35.951074  7974 caffe.cpp:315] Performing Backward
I1229 17:02:06.806897  7974 caffe.cpp:323] *** Benchmark begins ***
I1229 17:02:06.806952  7974 caffe.cpp:324] Testing for 1 iterations.
I1229 17:04:54.219861  7974 caffe.cpp:352] Iteration: 1 forward-backward time: 167404 ms.
I1229 17:04:54.219962  7974 caffe.cpp:355] Average time per layer: 
I1229 17:04:54.219977  7974 caffe.cpp:358]      conv4	forward: 77027.5 ms.
I1229 17:04:54.219990  7974 caffe.cpp:361]      conv4	backward: 90376.2 ms.
I1229 17:04:54.220029  7974 caffe.cpp:366] Average Forward pass: 77027.5 ms.
I1229 17:04:54.220043  7974 caffe.cpp:368] Average Backward pass: 90376.2 ms.
I1229 17:04:54.220059  7974 caffe.cpp:370] Average Forward-Backward: 167404 ms.
I1229 17:04:54.220074  7974 caffe.cpp:372] Total Time: 167404 ms.
I1229 17:04:54.220085  7974 caffe.cpp:373] *** Benchmark ends ***
==7974== Profiling application: ./caffe/build/tools/caffe time --model=proto_forceGradInput/conv4.prototxt --iterations=1 --gpu 0 --logtostderr=1
==7974== Profiling result:
==7974== Metric result:
"Device","Kernel","Invocations","Metric Name","Metric Description","Min","Max","Avg"
"Tesla K40c (0)","void scal_kernel<float, int=1, bool=1, int=6, int=5, int=5, int=3>(cublasTransposeParams<float>, float const *, float*, float const *)",256,"achieved_occupancy","Achieved Occupancy",0.123025,0.124564,0.124313
"Tesla K40c (0)","void scal_kernel<float, int=1, bool=1, int=6, int=5, int=5, int=3>(cublasTransposeParams<float>, float const *, float*, float const *)",256,"ipc","Executed IPC",0.380997,0.787170,0.518749
"Tesla K40c (0)","void scal_kernel<float, int=1, bool=1, int=6, int=5, int=5, int=3>(cublasTransposeParams<float>, float const *, float*, float const *)",256,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla K40c (0)","void scal_kernel<float, int=1, bool=1, int=6, int=5, int=5, int=3>(cublasTransposeParams<float>, float const *, float*, float const *)",256,"gld_efficiency","Global Memory Load Efficiency",0.000000%,0.000000%,0.000000%
"Tesla K40c (0)","void scal_kernel<float, int=1, bool=1, int=6, int=5, int=5, int=3>(cublasTransposeParams<float>, float const *, float*, float const *)",256,"gst_efficiency","Global Memory Store Efficiency",92.592593%,92.592593%,92.592593%
"Tesla K40c (0)","void scal_kernel<float, int=1, bool=1, int=6, int=5, int=5, int=3>(cublasTransposeParams<float>, float const *, float*, float const *)",256,"shared_efficiency","Shared Memory Efficiency",0.000000%,0.000000%,0.000000%
"Tesla K40c (0)","void gemmk1_kernel<float, int=256, int=5, bool=0, bool=0, bool=0, bool=0>(cublasGemmk1Params<float>, float const *, float const *, float*)",256,"achieved_occupancy","Achieved Occupancy",0.125868,0.130869,0.128608
"Tesla K40c (0)","void gemmk1_kernel<float, int=256, int=5, bool=0, bool=0, bool=0, bool=0>(cublasGemmk1Params<float>, float const *, float const *, float*)",256,"ipc","Executed IPC",0.185617,0.269931,0.221244
"Tesla K40c (0)","void gemmk1_kernel<float, int=256, int=5, bool=0, bool=0, bool=0, bool=0>(cublasGemmk1Params<float>, float const *, float const *, float*)",256,"warp_execution_efficiency","Warp Execution Efficiency",84.865416%,84.865416%,84.865416%
"Tesla K40c (0)","void gemmk1_kernel<float, int=256, int=5, bool=0, bool=0, bool=0, bool=0>(cublasGemmk1Params<float>, float const *, float const *, float*)",256,"gld_efficiency","Global Memory Load Efficiency",86.206897%,86.206897%,86.206897%
"Tesla K40c (0)","void gemmk1_kernel<float, int=256, int=5, bool=0, bool=0, bool=0, bool=0>(cublasGemmk1Params<float>, float const *, float const *, float*)",256,"gst_efficiency","Global Memory Store Efficiency",86.206897%,86.206897%,86.206897%
"Tesla K40c (0)","void gemmk1_kernel<float, int=256, int=5, bool=0, bool=0, bool=0, bool=0>(cublasGemmk1Params<float>, float const *, float const *, float*)",256,"shared_efficiency","Shared Memory Efficiency",39.228220%,39.228220%,39.228220%
"Tesla K40c (0)","void caffe::col2im_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, int, caffe::col2im_gpu_kernel<float>*)",256,"achieved_occupancy","Achieved Occupancy",0.498574,0.525397,0.516243
"Tesla K40c (0)","void caffe::col2im_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, int, caffe::col2im_gpu_kernel<float>*)",256,"ipc","Executed IPC",0.896025,0.951297,0.920904
"Tesla K40c (0)","void caffe::col2im_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, int, caffe::col2im_gpu_kernel<float>*)",256,"warp_execution_efficiency","Warp Execution Efficiency",74.249325%,74.249325%,74.249325%
"Tesla K40c (0)","void caffe::col2im_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, int, caffe::col2im_gpu_kernel<float>*)",256,"gld_efficiency","Global Memory Load Efficiency",28.363047%,28.363047%,28.363047%
"Tesla K40c (0)","void caffe::col2im_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, int, caffe::col2im_gpu_kernel<float>*)",256,"gst_efficiency","Global Memory Store Efficiency",100.000000%,100.000000%,100.000000%
"Tesla K40c (0)","void caffe::col2im_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, int, caffe::col2im_gpu_kernel<float>*)",256,"shared_efficiency","Shared Memory Efficiency",0.000000%,0.000000%,0.000000%
"Tesla K40c (0)","void caffe::im2col_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, caffe::im2col_gpu_kernel<float>*)",512,"achieved_occupancy","Achieved Occupancy",0.393871,0.400825,0.397539
"Tesla K40c (0)","void caffe::im2col_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, caffe::im2col_gpu_kernel<float>*)",512,"ipc","Executed IPC",1.021313,1.082652,1.059510
"Tesla K40c (0)","void caffe::im2col_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, caffe::im2col_gpu_kernel<float>*)",512,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla K40c (0)","void caffe::im2col_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, caffe::im2col_gpu_kernel<float>*)",512,"gld_efficiency","Global Memory Load Efficiency",56.451613%,56.451613%,56.451613%
"Tesla K40c (0)","void caffe::im2col_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, caffe::im2col_gpu_kernel<float>*)",512,"gst_efficiency","Global Memory Store Efficiency",86.389281%,86.389281%,86.389281%
"Tesla K40c (0)","void caffe::im2col_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, caffe::im2col_gpu_kernel<float>*)",512,"shared_efficiency","Shared Memory Efficiency",0.000000%,0.000000%,0.000000%
"Tesla K40c (0)","sgemm_sm35_ldg_tn_32x16x64x8x16",256,"achieved_occupancy","Achieved Occupancy",0.343612,0.345071,0.344269
"Tesla K40c (0)","sgemm_sm35_ldg_tn_32x16x64x8x16",256,"ipc","Executed IPC",2.671329,2.727418,2.697304
"Tesla K40c (0)","sgemm_sm35_ldg_tn_32x16x64x8x16",256,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla K40c (0)","sgemm_sm35_ldg_tn_32x16x64x8x16",256,"gld_efficiency","Global Memory Load Efficiency",25.000000%,25.000000%,25.000000%
"Tesla K40c (0)","sgemm_sm35_ldg_tn_32x16x64x8x16",256,"gst_efficiency","Global Memory Store Efficiency",25.000000%,25.000000%,25.000000%
"Tesla K40c (0)","sgemm_sm35_ldg_tn_32x16x64x8x16",256,"shared_efficiency","Shared Memory Efficiency",124.863646%,125.006363%,124.933172%
"Tesla K40c (0)","void sgemm_largek_lds64<bool=0, bool=0, int=5, int=5, int=4, int=4, int=4, int=32>(float*, float const *, float const *, int, int, int, int, int, int, float const *, float const *, float, float, int, int, int*, int*)",256,"achieved_occupancy","Achieved Occupancy",0.597649,0.665981,0.631105
"Tesla K40c (0)","void sgemm_largek_lds64<bool=0, bool=0, int=5, int=5, int=4, int=4, int=4, int=32>(float*, float const *, float const *, int, int, int, int, int, int, float const *, float const *, float, float, int, int, int*, int*)",256,"ipc","Executed IPC",2.113489,2.339700,2.215221
"Tesla K40c (0)","void sgemm_largek_lds64<bool=0, bool=0, int=5, int=5, int=4, int=4, int=4, int=32>(float*, float const *, float const *, int, int, int, int, int, int, float const *, float const *, float, float, int, int, int*, int*)",256,"warp_execution_efficiency","Warp Execution Efficiency",99.636087%,99.716174%,99.675900%
"Tesla K40c (0)","void sgemm_largek_lds64<bool=0, bool=0, int=5, int=5, int=4, int=4, int=4, int=32>(float*, float const *, float const *, int, int, int, int, int, int, float const *, float const *, float, float, int, int, int*, int*)",256,"gst_efficiency","Global Memory Store Efficiency",42.972103%,42.972103%,42.972103%
"Tesla K40c (0)","void sgemm_largek_lds64<bool=0, bool=0, int=5, int=5, int=4, int=4, int=4, int=32>(float*, float const *, float const *, int, int, int, int, int, int, float const *, float const *, float, float, int, int, int*, int*)",256,"shared_efficiency","Shared Memory Efficiency",94.415715%,94.416655%,94.416628%
"Tesla K40c (0)","sgemm_sm35_ldg_nt_64x16x64x16x16",256,"achieved_occupancy","Achieved Occupancy",0.345796,0.357074,0.351317
"Tesla K40c (0)","sgemm_sm35_ldg_nt_64x16x64x16x16",256,"ipc","Executed IPC",3.750630,3.849447,3.796908
"Tesla K40c (0)","sgemm_sm35_ldg_nt_64x16x64x16x16",256,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla K40c (0)","sgemm_sm35_ldg_nt_64x16x64x16x16",256,"gld_efficiency","Global Memory Load Efficiency",0.000000%,0.000000%,0.000000%
"Tesla K40c (0)","sgemm_sm35_ldg_nt_64x16x64x16x16",256,"gst_efficiency","Global Memory Store Efficiency",78.125000%,78.125000%,78.125000%
"Tesla K40c (0)","sgemm_sm35_ldg_nt_64x16x64x16x16",256,"shared_efficiency","Shared Memory Efficiency",165.271800%,165.271800%,165.271800%
"Tesla K40c (0)","void gemv2T_kernel_val<float, int=128, int=16, int=2, int=2, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",256,"achieved_occupancy","Achieved Occupancy",0.066535,0.066666,0.066585
"Tesla K40c (0)","void gemv2T_kernel_val<float, int=128, int=16, int=2, int=2, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",256,"ipc","Executed IPC",0.173279,0.224901,0.198050
"Tesla K40c (0)","void gemv2T_kernel_val<float, int=128, int=16, int=2, int=2, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",256,"warp_execution_efficiency","Warp Execution Efficiency",79.857513%,79.857513%,79.857513%
"Tesla K40c (0)","void gemv2T_kernel_val<float, int=128, int=16, int=2, int=2, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",256,"gld_efficiency","Global Memory Load Efficiency",79.411765%,79.411765%,79.411765%
"Tesla K40c (0)","void gemv2T_kernel_val<float, int=128, int=16, int=2, int=2, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",256,"gst_efficiency","Global Memory Store Efficiency",25.000000%,25.000000%,25.000000%
"Tesla K40c (0)","void gemv2T_kernel_val<float, int=128, int=16, int=2, int=2, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",256,"shared_efficiency","Shared Memory Efficiency",26.562500%,26.562500%,26.562500%
==7974== Warning: One or more events or metrics can't be profiled. Rerun with "--print-gpu-trace" for detail.
